{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import torch.nn as nn\n",
    "from skimage import io, transform, color\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import dataset, dataloader, Dataset\n",
    "from torchvision import transforms, utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://github.com/Spandan-Madan/Pytorch_fine_tuning_Tutorial/blob/master/main_fine_tuning.py\n",
    "# looks how the model is trained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget http://saliency.mit.edu/trainSet.zip -O /content/drive/MyDrive/data/trainSet.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/data/trainSet.zip -d /content/drive/MyDrive/data/q1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/1-1is0/deep-projects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1700, 3)\n",
      "Test: (300, 3)\n"
     ]
    }
   ],
   "source": [
    "from dataloader import load_data, ImageDataset, Rescale, ToTensor\n",
    "\n",
    "# path = \"/content/drive/MyDrive/data/q1/testSet/Stimuli/*/*.jpg\"\n",
    "path = \"data/Stimuli/*/*.jpg\"\n",
    "train_df, test_df = load_data(path)\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Test:\", test_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(\n",
    "    train_df,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            Rescale((320, 240)),\n",
    "            # RandomCrop(224),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = ImageDataset(\n",
    "    test_df,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            Rescale((320, 240)),\n",
    "            # RandomCrop(224),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=4, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=4, shuffle=True, num_workers=2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (local_response_norm): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (max_pool1): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (max_pool2): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv6): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (conv7): Conv2d(128, 64, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5))\n",
      "  (conv8): Conv2d(64, 16, kernel_size=(11, 11), stride=(1, 1), padding=(5, 5))\n",
      "  (conv9): Conv2d(16, 1, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6))\n",
      "  (deconv): ConvTranspose2d(1, 1, kernel_size=(8, 8), stride=(4, 4), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Net\n",
    "\n",
    "net = Net().to(device)\n",
    "net.initialize_weights()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR, ExponentialLR, StepLR\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 22\n",
      "epoch 4 0.0510649425400929\n",
      "running loss 1.1234287358820438\n",
      "val 4\n",
      "epoch 4 0.04862430295906961\n",
      "running loss 0.19449721183627844\n",
      "train 22\n",
      "epoch 5 0.05106494228609584\n",
      "running loss 1.1234287302941084\n",
      "val 4\n",
      "epoch 5 0.048624304588884115\n",
      "running loss 0.19449721835553646\n",
      "train 22\n",
      "epoch 6 0.05106494190510024\n",
      "running loss 1.1234287219122052\n",
      "val 4\n",
      "epoch 6 0.04862430552020669\n",
      "running loss 0.19449722208082676\n",
      "train 22\n",
      "epoch 7 0.05106494143943895\n",
      "running loss 1.123428711667657\n",
      "val 4\n",
      "epoch 7 0.04862430435605347\n",
      "running loss 0.1944972174242139\n",
      "train 22\n",
      "epoch 8 0.05106494160877033\n",
      "running loss 1.1234287153929472\n",
      "val 4\n",
      "epoch 8 0.048624305287376046\n",
      "running loss 0.19449722114950418\n",
      "train 22\n",
      "epoch 9 0.051064941100776196\n",
      "running loss 1.1234287042170763\n",
      "val 4\n",
      "epoch 9 0.04862430365756154\n",
      "running loss 0.19449721463024616\n",
      "train 22\n",
      "epoch 10 0.05106494182043455\n",
      "running loss 1.12342872004956\n",
      "val 4\n",
      "epoch 10 0.04862430621869862\n",
      "running loss 0.19449722487479448\n",
      "train 22\n",
      "epoch 11 0.05106494143943895\n",
      "running loss 1.123428711667657\n",
      "val 4\n",
      "epoch 11 0.04862430412322283\n",
      "running loss 0.1944972164928913\n",
      "train 22\n",
      "epoch 12 0.05106494228609584\n",
      "running loss 1.1234287302941084\n",
      "val 4\n",
      "epoch 12 0.048624306451529264\n",
      "running loss 0.19449722580611706\n",
      "train 22\n",
      "epoch 13 0.051064941502938214\n",
      "running loss 1.1234287130646408\n",
      "val 4\n",
      "epoch 13 0.048624304588884115\n",
      "running loss 0.19449721835553646\n",
      "train 22\n",
      "epoch 14 0.051064942413094366\n",
      "running loss 1.1234287330880761\n",
      "val 4\n",
      "epoch 14 0.04862430598586798\n",
      "running loss 0.1944972239434719\n",
      "train 22\n",
      "epoch 15 0.051064941862767395\n",
      "running loss 1.1234287209808826\n",
      "val 4\n",
      "epoch 15 0.0486243034247309\n",
      "running loss 0.1944972136989236\n",
      "train 22\n",
      "epoch 16 0.05106494084677913\n",
      "running loss 1.1234286986291409\n",
      "val 4\n",
      "epoch 16 0.04862430412322283\n",
      "running loss 0.1944972164928913\n",
      "train 22\n",
      "epoch 17 0.05106494093144482\n",
      "running loss 1.123428700491786\n",
      "val 4\n",
      "epoch 17 0.048624304588884115\n",
      "running loss 0.19449721835553646\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m: trainloader,\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m: testloader,\n\u001B[1;32m      6\u001B[0m }\n\u001B[1;32m      7\u001B[0m dataset_size \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mlen\u001B[39m(train_dataset),\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mlen\u001B[39m(test_dataset),\n\u001B[1;32m     10\u001B[0m }\n\u001B[0;32m---> 12\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./state\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     22\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(res)\n",
      "File \u001B[0;32m~/uni/deep-vision/hw2/q1/model.py:117\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(data_loader, dataset_size, model, criterion, optimizer, scheduler, epochs, device, path)\u001B[0m\n\u001B[1;32m    114\u001B[0m     # print statistics\n\u001B[1;32m    115\u001B[0m     # print(\"data shape\", data[\"image\"].shape)\n\u001B[1;32m    116\u001B[0m     now_batch_size = data[\"image\"].size()[0]\n\u001B[0;32m--> 117\u001B[0m     # print(\"len dataloader\", dataset_size[phase], \"now batch size\", now_batch_size)\n\u001B[1;32m    118\u001B[0m     running_loss += loss.item() * now_batch_size\n\u001B[1;32m    119\u001B[0m # add loss at the end of each iteration\n\u001B[1;32m    120\u001B[0m # loss_history.append(running_loss)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from model import train_model\n",
    "\n",
    "dataloader = {\n",
    "    \"train\": trainloader,\n",
    "    \"val\": testloader,\n",
    "}\n",
    "dataset_size = {\n",
    "    \"train\": len(train_dataset),\n",
    "    \"val\": len(test_dataset),\n",
    "}\n",
    "\n",
    "res = train_model(\n",
    "    data_loader=dataloader,\n",
    "    model=net,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    epochs=20,\n",
    "    dataset_size=dataset_size,\n",
    "    path=\"./state\"\n",
    ")\n",
    "\n",
    "\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mm = Net()\n",
    "mm.load_state_dict(torch.load(\"./model_01.pth\"))\n",
    "mm.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = mm(data[\"image\"].float())\n",
    "i.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = i[2, :, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(sam.permute(1, 2, 0).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(data[\"fix_map\"][2].permute(1, 2, 0).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i[0, :, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 96, 7, stride=1, padding=3)\n",
    "local_response_norm = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75)\n",
    "max_pool1 = nn.MaxPool2d((3, 3), stride=2)\n",
    "conv2 = nn.Conv2d(96, 256, 5, stride=1, padding=2)\n",
    "max_pool2 = nn.MaxPool2d((3, 3), stride=2, padding=0)\n",
    "conv3 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "conv4 = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2)\n",
    "conv5 = nn.Conv2d(512, 512, kernel_size=5, stride=1, padding=2)\n",
    "conv6 = nn.Conv2d(512, 256, kernel_size=7, stride=1, padding=3)\n",
    "conv7 = nn.Conv2d(256, 128, kernel_size=11, stride=1, padding=5)\n",
    "conv8 = nn.Conv2d(128, 32, kernel_size=11, stride=1, padding=5)\n",
    "conv9 = nn.Conv2d(32, 1, kernel_size=13, stride=1, padding=6)\n",
    "deconv = nn.ConvTranspose2d(1, 1, kernel_size=8, stride=4, bias=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 320, 240])\n"
     ]
    }
   ],
   "source": [
    "img = train_dataset[0][\"image\"].unsqueeze(0)\n",
    "print(img.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out1: torch.Size([1, 96, 320, 240])\n",
      "out2: torch.Size([1, 96, 320, 240])\n",
      "out3: torch.Size([1, 96, 159, 119])\n",
      "out4: torch.Size([1, 256, 159, 119])\n",
      "out5: torch.Size([1, 256, 79, 59])\n",
      "out6: torch.Size([1, 512, 79, 59])\n",
      "out7: torch.Size([1, 512, 79, 59])\n",
      "out8: torch.Size([1, 512, 79, 59])\n",
      "out9: torch.Size([1, 256, 79, 59])\n",
      "out10: torch.Size([1, 128, 79, 59])\n",
      "out11: torch.Size([1, 32, 79, 59])\n",
      "out12: torch.Size([1, 1, 79, 59])\n",
      "out13: torch.Size([1, 1, 320, 240])\n"
     ]
    }
   ],
   "source": [
    "out1 = conv1(img)\n",
    "print(\"out1:\", out1.shape)\n",
    "out2 = local_response_norm(out1)\n",
    "print(\"out2:\", out2.shape)\n",
    "out3 = max_pool1(out2)\n",
    "print(\"out3:\", out3.shape)\n",
    "out4 = conv2(out3)\n",
    "print(\"out4:\", out4.shape)\n",
    "out5 = max_pool2(out4)\n",
    "print(\"out5:\", out5.shape)\n",
    "out6 = conv3(out5)\n",
    "print(\"out6:\", out6.shape)\n",
    "out7 = conv4(out6)\n",
    "print(\"out7:\", out7.shape)\n",
    "out8 = conv5(out7)\n",
    "print(\"out8:\", out8.shape)\n",
    "out9 = conv6(out8)\n",
    "print(\"out9:\", out9.shape)\n",
    "out10 = conv7(out9)\n",
    "print(\"out10:\", out10.shape)\n",
    "out11 = conv8(out10)\n",
    "print(\"out11:\", out11.shape)\n",
    "out12 = conv9(out11)\n",
    "print(\"out12:\", out12.shape)\n",
    "out13 = deconv(out12)\n",
    "print(\"out13:\", out13.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 48, kernel_size=7, stride=1, padding=3)\n",
    "local_response_norm = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75)\n",
    "max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "conv2 = nn.Conv2d(48, 128, 5, stride=1, padding=2)\n",
    "max_pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "conv4 = nn.Conv2d(256, 256, kernel_size=5, stride=1, padding=2)\n",
    "conv5 = nn.Conv2d(256, 256, kernel_size=5, stride=1, padding=2)\n",
    "conv6 = nn.Conv2d(256, 128, kernel_size=7, stride=1, padding=3)\n",
    "conv7 = nn.Conv2d(128, 64, kernel_size=11, stride=1, padding=5)\n",
    "conv8 = nn.Conv2d(64, 16, kernel_size=11, stride=1, padding=5)\n",
    "conv9 = nn.Conv2d(16, 1, kernel_size=13, stride=1, padding=6)\n",
    "deconv = nn.ConvTranspose2d(1, 1, kernel_size=8, stride=4, bias=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out1: torch.Size([1, 48, 320, 240])\n",
      "out2: torch.Size([1, 48, 320, 240])\n",
      "out3: torch.Size([1, 48, 159, 119])\n",
      "out4: torch.Size([1, 128, 159, 119])\n",
      "out5: torch.Size([1, 128, 79, 59])\n",
      "out6: torch.Size([1, 256, 79, 59])\n",
      "out7: torch.Size([1, 256, 79, 59])\n",
      "out8: torch.Size([1, 256, 79, 59])\n",
      "out9: torch.Size([1, 128, 79, 59])\n",
      "out10: torch.Size([1, 64, 79, 59])\n",
      "out11: torch.Size([1, 16, 79, 59])\n",
      "out12: torch.Size([1, 1, 79, 59])\n",
      "out13: torch.Size([1, 1, 320, 240])\n"
     ]
    }
   ],
   "source": [
    "out1 = conv1(img)\n",
    "print(\"out1:\", out1.shape)\n",
    "out2 = local_response_norm(out1)\n",
    "print(\"out2:\", out2.shape)\n",
    "out3 = max_pool1(out2)\n",
    "print(\"out3:\", out3.shape)\n",
    "out4 = conv2(out3)\n",
    "print(\"out4:\", out4.shape)\n",
    "out5 = max_pool2(out4)\n",
    "print(\"out5:\", out5.shape)\n",
    "out6 = conv3(out5)\n",
    "print(\"out6:\", out6.shape)\n",
    "out7 = conv4(out6)\n",
    "print(\"out7:\", out7.shape)\n",
    "out8 = conv5(out7)\n",
    "print(\"out8:\", out8.shape)\n",
    "out9 = conv6(out8)\n",
    "print(\"out9:\", out9.shape)\n",
    "out10 = conv7(out9)\n",
    "print(\"out10:\", out10.shape)\n",
    "out11 = conv8(out10)\n",
    "print(\"out11:\", out11.shape)\n",
    "out12 = conv9(out11)\n",
    "print(\"out12:\", out12.shape)\n",
    "out13 = deconv(out12)\n",
    "print(\"out13:\", out13.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}